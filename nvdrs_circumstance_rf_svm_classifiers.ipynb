{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16537,"status":"ok","timestamp":1705638980929,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"iKLItT_m2ady","outputId":"65b8b4c8-2e32-4655-bf87-68903ff79b26"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7836f1d042d0>"]},"metadata":{},"execution_count":1}],"source":["import pandas as pd\n","import numpy\n","from sklearn import model_selection\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import classification_report\n","from sklearn import feature_selection\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.ensemble import RandomForestClassifier\n","import seaborn as sn\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.naive_bayes import MultinomialNB\n","# Import modules for evaluation purposes\n","# Import libraries for predcton\n","from sklearn import metrics\n","from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve, auc, f1_score\n","import nltk\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","\n","\n","\n","import torch\n","torch.cuda.empty_cache()\n","import seaborn as sns\n","import json\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","import logging\n","logging.basicConfig(level=logging.ERROR)\n","from google.colab import output\n","import seaborn as sn\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","#GPU usage setup\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","import random\n","random.seed(1)\n","np.random.seed(1)\n","torch.cuda.manual_seed(1)\n","torch.manual_seed(1)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yevoamnq44vX"},"outputs":[],"source":["# mount drive to access data\n","from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LOmwkWLN5OxK"},"outputs":[],"source":["\n","%cd /content/drive/MyDrive/nvdrs_narratives/round_1_annotation_topics\n","\n","%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1677,"status":"ok","timestamp":1705615257003,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"4gAOw8Tk5SUZ","outputId":"0a796e12-d2c4-4f8e-a241-ad52f60d027c"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 100 entries, 0 to 49\n","Data columns (total 10 columns):\n"," #   Column                      Non-Null Count  Dtype \n","---  ------                      --------------  ----- \n"," 0   IncidentID                  100 non-null    int64 \n"," 1   NarrativeLE                 60 non-null     object\n"," 2   matched_term_x              82 non-null     object\n"," 3   LE_CircumstancesOtherText   5 non-null      object\n"," 4   NarrativeCME                57 non-null     object\n"," 5   matched_term_y              76 non-null     object\n"," 6   CME_CircumstancesOtherText  2 non-null      object\n"," 7   topic_name                  100 non-null    object\n"," 8   topic_relevant_annotation   100 non-null    int64 \n"," 9   comments                    25 non-null     object\n","dtypes: int64(2), object(8)\n","memory usage: 8.6+ KB\n"]}],"source":["# Read the Sample first round csv file\n","#df = pd.read_csv(\"pet_sampled_dw_completed.csv\")\n","\n","df1 = pd.read_csv(\"eviction or move_sampled_sp_completed.csv\")\n","df2 = pd.read_csv(\"eviction or move_sample_0_sp_completed.csv\")\n","# Bind/concatenate rows from additional sample, make sure we preserve column names\n","df = pd.concat([df1, df2])\n","\n","df.info()\n","topic_name = \"eviction or move\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuAUEe_U5J16"},"outputs":[],"source":["df['label'] = df['topic_relevant_annotation']\n","df.drop(['IncidentID','LE_CircumstancesOtherText','CME_CircumstancesOtherText','topic_name','comments'], axis=1)\n","del df['IncidentID'], df['LE_CircumstancesOtherText'],df['CME_CircumstancesOtherText'], df['topic_name'], df['comments'], df['topic_relevant_annotation']\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1705615259343,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"mbf1chDYP4nv","outputId":"29dc4286-62ef-446d-81fb-5ce0fea1ca7c","collapsed":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  text           matched_term  \\\n","0    V was W/M/46. V was found at his residence, ex...             ['moving']   \n","1    V was W/M/46. V was found in his apartment in ...             ['moving']   \n","2    The V is a 60 year old White male. The V was f...  ['eviction', 'moved']   \n","3    The V is a 60 year old White male. The V was f...            ['evicted']   \n","4    The V, a 27 year old white male, died of a sel...              ['moved']   \n","..                                                 ...                    ...   \n","112  State and local police were notified of a deat...              ['moved']   \n","113  V is a 28 year old white male who was found de...       ['out of state']   \n","114  PA 2019 Incident: 253 was merged with PA 2019 ...              ['moved']   \n","115  V1 (92, white, female) and V2 (62, white, male...              ['moved']   \n","116  V is a 25 year old Multi/C non-Hispanic Male w...            ['to move']   \n","\n","    label  \n","0       1  \n","1       1  \n","2       1  \n","3       1  \n","4       1  \n","..    ...  \n","112     1  \n","113     0  \n","114     0  \n","115     0  \n","116     0  \n","\n","[117 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-0e270303-3029-4114-a81e-8c38f383a37f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>matched_term</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>V was W/M/46. V was found at his residence, ex...</td>\n","      <td>['moving']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>V was W/M/46. V was found in his apartment in ...</td>\n","      <td>['moving']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The V is a 60 year old White male. The V was f...</td>\n","      <td>['eviction', 'moved']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The V is a 60 year old White male. The V was f...</td>\n","      <td>['evicted']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The V, a 27 year old white male, died of a sel...</td>\n","      <td>['moved']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>112</th>\n","      <td>State and local police were notified of a deat...</td>\n","      <td>['moved']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>V is a 28 year old white male who was found de...</td>\n","      <td>['out of state']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>114</th>\n","      <td>PA 2019 Incident: 253 was merged with PA 2019 ...</td>\n","      <td>['moved']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>115</th>\n","      <td>V1 (92, white, female) and V2 (62, white, male...</td>\n","      <td>['moved']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>116</th>\n","      <td>V is a 25 year old Multi/C non-Hispanic Male w...</td>\n","      <td>['to move']</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>117 rows Ã— 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e270303-3029-4114-a81e-8c38f383a37f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0e270303-3029-4114-a81e-8c38f383a37f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0e270303-3029-4114-a81e-8c38f383a37f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4afb6335-45e0-4f4b-842c-745629ba20fb\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4afb6335-45e0-4f4b-842c-745629ba20fb')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4afb6335-45e0-4f4b-842c-745629ba20fb button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_5af71aa3-654d-47f9-9b07-9740d76a4a43\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('transformed_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_5af71aa3-654d-47f9-9b07-9740d76a4a43 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('transformed_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":23}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Assuming df is your existing DataFrame\n","# df = pd.DataFrame(...)  # your original DataFrame\n","\n","def transform_dataframe(original_df):\n","    # Create an empty DataFrame with the desired structure\n","    transformed_df = pd.DataFrame(columns=['text', 'matched_term', 'label'])\n","\n","    # Iterate over each row in the original DataFrame\n","    for idx, row in original_df.iterrows():\n","        # Logic for handling NarrativeLE and NarrativeCME\n","        if pd.isna(row['NarrativeLE']) or row['NarrativeLE'] == '':\n","            transformed_df = transformed_df.append({\n","                'text': row['NarrativeCME'],\n","                'matched_term': row['matched_term_y'],\n","                'label': row['label']\n","            }, ignore_index=True)\n","        elif pd.isna(row['NarrativeCME']) or row['NarrativeCME'] == '':\n","            transformed_df = transformed_df.append({\n","                'text': row['NarrativeLE'],\n","                'matched_term': row['matched_term_x'],\n","                'label': row['label']\n","            }, ignore_index=True)\n","        else:\n","            # Create two new rows if both columns have values\n","            transformed_df = transformed_df.append([\n","                {\n","                    'text': row['NarrativeLE'],\n","                    'matched_term': row['matched_term_x'],\n","                    'label': row['label']\n","                },\n","                {\n","                    'text': row['NarrativeCME'],\n","                    'matched_term': row['matched_term_y'],\n","                    'label': row['label']\n","                }\n","            ], ignore_index=True)\n","\n","    return transformed_df\n","\n","# Apply the transformation\n","transformed_df = transform_dataframe(df)\n","\n","# Output the transformed DataFrame\n","transformed_df\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":265,"status":"ok","timestamp":1705615263854,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"k5LiZ8115kM5","outputId":"8b5468e3-58e9-4f91-ba63-ffdc98d40979","collapsed":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  text           matched_term  \\\n","0    V was W/M/46. V was found at his residence, ex...             ['moving']   \n","1    V was W/M/46. V was found in his apartment in ...             ['moving']   \n","2    The V is a 60 year old White male. The V was f...  ['eviction', 'moved']   \n","3    The V is a 60 year old White male. The V was f...            ['evicted']   \n","4    The V, a 27 year old white male, died of a sel...              ['moved']   \n","..                                                 ...                    ...   \n","112  State and local police were notified of a deat...              ['moved']   \n","113  V is a 28 year old white male who was found de...       ['out of state']   \n","114  PA 2019 Incident: 253 was merged with PA 2019 ...              ['moved']   \n","115  V1 (92, white, female) and V2 (62, white, male...              ['moved']   \n","116  V is a 25 year old Multi/C non-Hispanic Male w...            ['to move']   \n","\n","     label  \n","0        1  \n","1        1  \n","2        1  \n","3        1  \n","4        1  \n","..     ...  \n","112      1  \n","113      0  \n","114      0  \n","115      0  \n","116      0  \n","\n","[117 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-3c23c49e-3f0b-4f2c-9da1-64d8f52e23b0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>matched_term</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>V was W/M/46. V was found at his residence, ex...</td>\n","      <td>['moving']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>V was W/M/46. V was found in his apartment in ...</td>\n","      <td>['moving']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The V is a 60 year old White male. The V was f...</td>\n","      <td>['eviction', 'moved']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The V is a 60 year old White male. The V was f...</td>\n","      <td>['evicted']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The V, a 27 year old white male, died of a sel...</td>\n","      <td>['moved']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>112</th>\n","      <td>State and local police were notified of a deat...</td>\n","      <td>['moved']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>V is a 28 year old white male who was found de...</td>\n","      <td>['out of state']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>114</th>\n","      <td>PA 2019 Incident: 253 was merged with PA 2019 ...</td>\n","      <td>['moved']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>115</th>\n","      <td>V1 (92, white, female) and V2 (62, white, male...</td>\n","      <td>['moved']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>116</th>\n","      <td>V is a 25 year old Multi/C non-Hispanic Male w...</td>\n","      <td>['to move']</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>117 rows Ã— 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c23c49e-3f0b-4f2c-9da1-64d8f52e23b0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3c23c49e-3f0b-4f2c-9da1-64d8f52e23b0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3c23c49e-3f0b-4f2c-9da1-64d8f52e23b0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-dc56fe3f-bcd4-484d-ba3c-977365aafcee\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dc56fe3f-bcd4-484d-ba3c-977365aafcee')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-dc56fe3f-bcd4-484d-ba3c-977365aafcee button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_b6bcd03e-fed5-4dff-a947-98f8c0faf1a9\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_b6bcd03e-fed5-4dff-a947-98f8c0faf1a9 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":24}],"source":["df = transformed_df\n","cols = ['text', 'matched_term']\n","df['text'] = df[cols].apply(lambda row: '</s>'.join(row.values.astype(str)), axis=1)\n","df[\"label\"] = df[\"label\"].astype(int)\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77336,"status":"ok","timestamp":1705615341186,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"hzlC-1t22_A0","outputId":"d316dc4c-12ac-45ed-df62-9b7017afbb30"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 3 candidates, totalling 15 fits\n","Fitting 5 folds for each of 27 candidates, totalling 135 fits\n","Fitting 5 folds for each of 3 candidates, totalling 15 fits\n","                     Model                                    Hyperparameters  \\\n","0  Multinomial Naive Bayes                                     {'alpha': 1.0}   \n","1            Random Forest  {'max_depth': None, 'min_samples_split': 5, 'n...   \n","2      Logistic Regression                                         {'C': 1.0}   \n","\n","   Accuracy  Positive Precision  Positive Recall  Positive F1  \\\n","0  0.652174            0.750000              0.3     0.428571   \n","1  0.521739            0.000000              0.0     0.000000   \n","2  0.739130            0.833333              0.5     0.625000   \n","\n","   Negative Precision  Negative Recall  Negative F1  Macro Precision  \\\n","0            0.750000              0.3     0.428571         0.750000   \n","1            0.000000              0.0     0.000000         0.000000   \n","2            0.833333              0.5     0.625000         0.833333   \n","\n","   Macro Recall  Macro F1            Timestamp  Duration (s)  \n","0           0.3  0.428571  2024-01-18 22:02:41      0.051706  \n","1           0.0  0.000000  2024-01-18 22:03:56     74.264679  \n","2           0.5  0.625000  2024-01-18 22:03:57      1.620149  \n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n","from datetime import datetime\n","import time\n","\n","skf = StratifiedKFold(n_splits=5)\n","X = df['text'].values\n","y = df['label'].values\n","\n","metrics = []\n","\n","skf = StratifiedKFold(n_splits=5)\n","\n","for train_index, test_index in skf.split(X, y):\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","\n","    vect = CountVectorizer(ngram_range=(1, 3), max_features=10000, stop_words=\"english\")\n","    X_train_dtm = vect.fit_transform(X_train)\n","    X_test_dtm = vect.transform(X_test)\n","\n","\n","# Define the parameter grids for Naive Bayes, Random Forest, and Logistic Regression\n","nb_param_grid = {\n","    'alpha': [0.1, 0.5, 1.0],  # Different alpha values for MultinomialNB\n","}\n","\n","rf_param_grid = {\n","    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n","    'max_depth': [None, 10, 20],  # Maximum depth of the trees\n","    'min_samples_split': [2, 5, 10],  # Minimum samples required to split an internal node\n","}\n","\n","lr_param_grid = {\n","    'C': [0.01, 0.1, 1.0],  # Regularization parameter for Logistic Regression\n","}\n","\n","# Create a list to store the results\n","results = []\n","\n","# Define a custom scoring function to prioritize precision for the positive class\n","positive_precision_scorer = make_scorer(precision_score, labels=[1], average='binary')\n","positive_recall_scorer = make_scorer(recall_score, labels=[1], average='binary')\n","positive_f1_scorer = make_scorer(f1_score, labels=[1], average='binary')\n","\n","# Define custom scoring functions for negative class\n","negative_precision_scorer = make_scorer(precision_score, labels=[0], average='binary')\n","negative_recall_scorer = make_scorer(recall_score, labels=[0], average='binary')\n","negative_f1_scorer = make_scorer(f1_score, labels=[0], average='binary')\n","\n","# Perform grid search for Naive Bayes\n","nb_grid_search = GridSearchCV(MultinomialNB(), nb_param_grid, cv=5, scoring='accuracy', verbose=1)\n","start_time = time.time()\n","nb_grid_search.fit(X_train_dtm, y_train)\n","end_time = time.time()\n","duration = end_time - start_time\n","\n","# Get the best hyperparameters and the corresponding model\n","best_nb_model = nb_grid_search.best_estimator_\n","best_nb_params = nb_grid_search.best_params_\n","\n","# Evaluate the Naive Bayes model on the test set\n","nb_test_predictions = best_nb_model.predict(X_test_dtm)\n","nb_accuracy = accuracy_score(y_test, nb_test_predictions)\n","nb_positive_precision = precision_score(y_test, nb_test_predictions, labels=[1], average='binary')\n","nb_positive_recall = recall_score(y_test, nb_test_predictions, labels=[1], average='binary')\n","nb_positive_f1 = f1_score(y_test, nb_test_predictions, labels=[1], average='binary')\n","nb_negative_precision = precision_score(y_test, nb_test_predictions, labels=[0], average='binary')\n","nb_negative_recall = recall_score(y_test, nb_test_predictions, labels=[0], average='binary')\n","nb_negative_f1 = f1_score(y_test, nb_test_predictions, labels=[0], average='binary')\n","nb_macro_precision = (nb_positive_precision + nb_negative_precision) / 2\n","nb_macro_recall = (nb_positive_recall + nb_negative_recall) / 2\n","nb_macro_f1 = (nb_positive_f1 + nb_negative_f1) / 2\n","\n","# Store the results for Naive Bayes\n","results.append({\n","    'Model': 'Multinomial Naive Bayes',\n","    'Hyperparameters': best_nb_params,\n","    'Accuracy': nb_accuracy,\n","    'Positive Precision': nb_positive_precision,\n","    'Positive Recall': nb_positive_recall,\n","    'Positive F1': nb_positive_f1,\n","    'Negative Precision': nb_negative_precision,\n","    'Negative Recall': nb_negative_recall,\n","    'Negative F1': nb_negative_f1,\n","    'Macro Precision': nb_macro_precision,\n","    'Macro Recall': nb_macro_recall,\n","    'Macro F1': nb_macro_f1,\n","    'Timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n","    'Duration (s)': duration\n","})\n","\n","# Perform grid search for Random Forest\n","rf_grid_search = GridSearchCV(RandomForestClassifier(random_state=1), rf_param_grid, cv=5, scoring='accuracy', verbose=1)\n","start_time = time.time()\n","rf_grid_search.fit(X_train_dtm, y_train)\n","end_time = time.time()\n","duration = end_time - start_time\n","\n","# Get the best hyperparameters and the corresponding model\n","best_rf_model = rf_grid_search.best_estimator_\n","best_rf_params = rf_grid_search.best_params_\n","\n","# Evaluate the Random Forest model on the test set\n","rf_test_predictions = best_rf_model.predict(X_test_dtm)\n","rf_accuracy = accuracy_score(y_test, rf_test_predictions)\n","rf_positive_precision = precision_score(y_test, rf_test_predictions, labels=[1], average='binary')\n","rf_positive_recall = recall_score(y_test, rf_test_predictions, labels=[1], average='binary')\n","rf_positive_f1 = f1_score(y_test, rf_test_predictions, labels=[1], average='binary')\n","rf_negative_precision = precision_score(y_test, rf_test_predictions, labels=[0], average='binary')\n","rf_negative_recall = recall_score(y_test, rf_test_predictions, labels=[0], average='binary')\n","rf_negative_f1 = f1_score(y_test, rf_test_predictions, labels=[0], average='binary')\n","rf_macro_precision = (rf_positive_precision + rf_negative_precision) / 2\n","rf_macro_recall = (rf_positive_recall + rf_negative_recall) / 2\n","rf_macro_f1 = (rf_positive_f1 + rf_negative_f1) / 2\n","\n","# Store the results for Random Forest\n","results.append({\n","    'Model': 'Random Forest',\n","    'Hyperparameters': best_rf_params,\n","    'Accuracy': rf_accuracy,\n","    'Positive Precision': rf_positive_precision,\n","    'Positive Recall': rf_positive_recall,\n","    'Positive F1': rf_positive_f1,\n","    'Negative Precision': rf_negative_precision,\n","    'Negative Recall': rf_negative_recall,\n","    'Negative F1': rf_negative_f1,\n","    'Macro Precision': rf_macro_precision,\n","    'Macro Recall': rf_macro_recall,\n","    'Macro F1': rf_macro_f1,\n","    'Timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n","    'Duration (s)': duration\n","})\n","\n","# Perform grid search for Logistic Regression\n","lr_grid_search = GridSearchCV(LogisticRegression(max_iter=1000), lr_param_grid, cv=5, scoring='accuracy', verbose=1)\n","start_time = time.time()\n","lr_grid_search.fit(X_train_dtm, y_train)\n","end_time = time.time()\n","duration = end_time - start_time\n","\n","# Get the best hyperparameters and the corresponding model\n","best_lr_model = lr_grid_search.best_estimator_\n","best_lr_params = lr_grid_search.best_params_\n","\n","# Evaluate the Logistic Regression model on the test set\n","lr_test_predictions = best_lr_model.predict(X_test_dtm)\n","lr_accuracy = accuracy_score(y_test, lr_test_predictions)\n","lr_positive_precision = precision_score(y_test, lr_test_predictions, labels=[1], average='binary')\n","lr_positive_recall = recall_score(y_test, lr_test_predictions, labels=[1], average='binary')\n","lr_positive_f1 = f1_score(y_test, lr_test_predictions, labels=[1], average='binary')\n","lr_negative_precision = precision_score(y_test, lr_test_predictions, labels=[0], average='binary')\n","lr_negative_recall = recall_score(y_test, lr_test_predictions, labels=[0], average='binary')\n","lr_negative_f1 = f1_score(y_test, lr_test_predictions, labels=[0], average='binary')\n","lr_macro_precision = (lr_positive_precision + lr_negative_precision) / 2\n","lr_macro_recall = (lr_positive_recall + lr_negative_recall) / 2\n","lr_macro_f1 = (lr_positive_f1 + lr_negative_f1) / 2\n","\n","# Store the results for Logistic Regression\n","results.append({\n","    'Model': 'Logistic Regression',\n","    'Hyperparameters': best_lr_params,\n","    'Accuracy': lr_accuracy,\n","    'Positive Precision': lr_positive_precision,\n","    'Positive Recall': lr_positive_recall,\n","    'Positive F1': lr_positive_f1,\n","    'Negative Precision': lr_negative_precision,\n","    'Negative Recall': lr_negative_recall,\n","    'Negative F1': lr_negative_f1,\n","    'Macro Precision': lr_macro_precision,\n","    'Macro Recall': lr_macro_recall,\n","    'Macro F1': lr_macro_f1,\n","    'Timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n","    'Duration (s)': duration\n","})\n","\n","# Create a DataFrame from the results\n","results_df = pd.DataFrame(results)\n","\n","# Print the results\n","print(results_df)\n","\n","# Save the results to a CSV file\n","results_df.to_csv(f'nvdrs_{topic_name}_model_results.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"C7nLxhuZjg7W"},"source":["# Best performers\n","\n","Bootsrap resampling best performers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U27Vk7bejim7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705615581994,"user_tz":300,"elapsed":190118,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"}},"outputId":"9d0661ea-0aad-4e48-c432-48eb4004400d"},"outputs":[{"output_type":"stream","name":"stdout","text":["                         Accuracy                       Positive Precision  \\\n","                             mean <lambda_0> <lambda_1>               mean   \n","Model                                                                        \n","Logistic Regression      0.584333   0.416667   0.791667           0.529941   \n","Multinomial Naive Bayes  0.748667   0.583333   0.916667           0.776624   \n","Random Forest            0.666167   0.458333   0.833333           0.634337   \n","\n","                                              Positive Recall             \\\n","                        <lambda_0> <lambda_1>            mean <lambda_0>   \n","Model                                                                      \n","Logistic Regression       0.312500   0.761975        0.821437   0.571429   \n","Multinomial Naive Bayes   0.499038   1.000000        0.638090   0.307500   \n","Random Forest             0.362879   0.900000        0.643980   0.356548   \n","\n","                                   Positive F1  ... Negative F1  \\\n","                        <lambda_1>        mean  ...  <lambda_1>   \n","Model                                           ...               \n","Logistic Regression       1.000000    0.636704  ...    0.823529   \n","Multinomial Naive Bayes   0.909091    0.688731  ...    0.888889   \n","Random Forest             0.909091    0.628921  ...    0.833333   \n","\n","                        Macro Precision                       Macro Recall  \\\n","                                   mean <lambda_0> <lambda_1>         mean   \n","Model                                                                        \n","Logistic Regression            0.529941   0.312500   0.761975     0.821437   \n","Multinomial Naive Bayes        0.776624   0.499038   1.000000     0.638090   \n","Random Forest                  0.634337   0.362879   0.900000     0.643980   \n","\n","                                               Macro F1                        \n","                        <lambda_0> <lambda_1>      mean <lambda_0> <lambda_1>  \n","Model                                                                          \n","Logistic Regression       0.571429   1.000000  0.636704   0.416667   0.823529  \n","Multinomial Naive Bayes   0.307500   0.909091  0.688731   0.400000   0.888889  \n","Random Forest             0.356548   0.909091  0.628921   0.374716   0.833333  \n","\n","[3 rows x 30 columns]\n","                         Accuracy                       Positive Precision  \\\n","                             mean <lambda_0> <lambda_1>               mean   \n","Model                                                                        \n","Logistic Regression      0.710083   0.500000   0.876042           0.605818   \n","Multinomial Naive Bayes  0.624667   0.458333   0.833333           0.552725   \n","Random Forest            0.663708   0.458333   0.833333           0.602298   \n","\n","                                              Positive Recall             \\\n","                        <lambda_0> <lambda_1>            mean <lambda_0>   \n","Model                                                                      \n","Logistic Regression       0.333333   0.866667        0.899404   0.666667   \n","Multinomial Naive Bayes   0.250000   0.875347        0.600885   0.300000   \n","Random Forest             0.250000   0.900000        0.597906   0.250000   \n","\n","                                   Positive F1  ... Negative F1  \\\n","                        <lambda_1>        mean  ...  <lambda_1>   \n","Model                                           ...               \n","Logistic Regression       1.000000    0.715471  ...    0.900000   \n","Multinomial Naive Bayes   0.888889    0.563273  ...    0.800000   \n","Random Forest             0.888889    0.587172  ...    0.823529   \n","\n","                        Macro Precision                       Macro Recall  \\\n","                                   mean <lambda_0> <lambda_1>         mean   \n","Model                                                                        \n","Logistic Regression            0.605818   0.333333   0.866667     0.899404   \n","Multinomial Naive Bayes        0.552725   0.250000   0.875347     0.600885   \n","Random Forest                  0.602298   0.250000   0.900000     0.597906   \n","\n","                                               Macro F1                        \n","                        <lambda_0> <lambda_1>      mean <lambda_0> <lambda_1>  \n","Model                                                                          \n","Logistic Regression       0.666667   1.000000  0.715471   0.476190   0.900000  \n","Multinomial Naive Bayes   0.300000   0.888889  0.563273   0.285714   0.800000  \n","Random Forest             0.250000   0.888889  0.587172   0.285714   0.823529  \n","\n","[3 rows x 30 columns]\n","                         Accuracy                       Positive Precision  \\\n","                             mean <lambda_0> <lambda_1>               mean   \n","Model                                                                        \n","Logistic Regression      0.436565   0.217391   0.652174           0.363365   \n","Multinomial Naive Bayes  0.656217   0.434783   0.827174           0.746388   \n","Random Forest            0.606348   0.391304   0.826087           0.620077   \n","\n","                                              Positive Recall             \\\n","                        <lambda_0> <lambda_1>            mean <lambda_0>   \n","Model                                                                      \n","Logistic Regression       0.083333   0.666667        0.400330   0.090909   \n","Multinomial Naive Bayes   0.000000   1.000000        0.306764   0.000000   \n","Random Forest             0.000000   1.000000        0.198418   0.000000   \n","\n","                                   Positive F1  ... Negative F1  \\\n","                        <lambda_1>        mean  ...  <lambda_1>   \n","Model                                           ...               \n","Logistic Regression       0.714286    0.370155  ...    0.640000   \n","Multinomial Naive Bayes   0.625000    0.416863  ...    0.727273   \n","Random Forest             0.500000    0.286915  ...    0.615385   \n","\n","                        Macro Precision                       Macro Recall  \\\n","                                   mean <lambda_0> <lambda_1>         mean   \n","Model                                                                        \n","Logistic Regression            0.363365   0.083333   0.666667     0.400330   \n","Multinomial Naive Bayes        0.746388   0.000000   1.000000     0.306764   \n","Random Forest                  0.620077   0.000000   1.000000     0.198418   \n","\n","                                               Macro F1                        \n","                        <lambda_0> <lambda_1>      mean <lambda_0> <lambda_1>  \n","Model                                                                          \n","Logistic Regression       0.090909   0.714286  0.370155        0.1   0.640000  \n","Multinomial Naive Bayes   0.000000   0.625000  0.416863        0.0   0.727273  \n","Random Forest             0.000000   0.500000  0.286915        0.0   0.615385  \n","\n","[3 rows x 30 columns]\n","                         Accuracy                       Positive Precision  \\\n","                             mean <lambda_0> <lambda_1>               mean   \n","Model                                                                        \n","Logistic Regression      0.652348   0.477174   0.826087              0.871   \n","Multinomial Naive Bayes  0.652348   0.477174   0.826087              0.871   \n","Random Forest            0.610435   0.391304   0.782609              0.622   \n","\n","                                              Positive Recall             \\\n","                        <lambda_0> <lambda_1>            mean <lambda_0>   \n","Model                                                                      \n","Logistic Regression            0.0        1.0        0.195238        0.0   \n","Multinomial Naive Bayes        0.0        1.0        0.195238        0.0   \n","Random Forest                  0.0        1.0        0.098815        0.0   \n","\n","                                   Positive F1  ... Negative F1  \\\n","                        <lambda_1>        mean  ...  <lambda_1>   \n","Model                                           ...               \n","Logistic Regression       0.454545    0.308173  ...      0.6250   \n","Multinomial Naive Bayes   0.454545    0.308173  ...      0.6250   \n","Random Forest             0.300833    0.166030  ...      0.4625   \n","\n","                        Macro Precision                       Macro Recall  \\\n","                                   mean <lambda_0> <lambda_1>         mean   \n","Model                                                                        \n","Logistic Regression               0.871        0.0        1.0     0.195238   \n","Multinomial Naive Bayes           0.871        0.0        1.0     0.195238   \n","Random Forest                     0.622        0.0        1.0     0.098815   \n","\n","                                               Macro F1                        \n","                        <lambda_0> <lambda_1>      mean <lambda_0> <lambda_1>  \n","Model                                                                          \n","Logistic Regression            0.0   0.454545  0.308173        0.0     0.6250  \n","Multinomial Naive Bayes        0.0   0.454545  0.308173        0.0     0.6250  \n","Random Forest                  0.0   0.300833  0.166030        0.0     0.4625  \n","\n","[3 rows x 30 columns]\n","                         Accuracy                       Positive Precision  \\\n","                             mean <lambda_0> <lambda_1>               mean   \n","Model                                                                        \n","Logistic Regression      0.731130   0.565217   0.913043           0.821362   \n","Multinomial Naive Bayes  0.600652   0.391304   0.782609           0.609894   \n","Random Forest            0.518348   0.304348   0.739130           0.000000   \n","\n","                                              Positive Recall             \\\n","                        <lambda_0> <lambda_1>            mean <lambda_0>   \n","Model                                                                      \n","Logistic Regression       0.428571        1.0        0.491659   0.199545   \n","Multinomial Naive Bayes   0.000000        1.0        0.190210   0.000000   \n","Random Forest             0.000000        0.0        0.000000   0.000000   \n","\n","                                   Positive F1  ... Negative F1  \\\n","                        <lambda_1>        mean  ...  <lambda_1>   \n","Model                                           ...               \n","Logistic Regression       0.800000    0.599001  ...    0.857143   \n","Multinomial Naive Bayes   0.454545    0.275329  ...    0.615385   \n","Random Forest             0.000000    0.000000  ...    0.000000   \n","\n","                        Macro Precision                       Macro Recall  \\\n","                                   mean <lambda_0> <lambda_1>         mean   \n","Model                                                                        \n","Logistic Regression            0.821362   0.428571        1.0     0.491659   \n","Multinomial Naive Bayes        0.609894   0.000000        1.0     0.190210   \n","Random Forest                  0.000000   0.000000        0.0     0.000000   \n","\n","                                               Macro F1                        \n","                        <lambda_0> <lambda_1>      mean <lambda_0> <lambda_1>  \n","Model                                                                          \n","Logistic Regression       0.199545   0.800000  0.599001   0.285714   0.857143  \n","Multinomial Naive Bayes   0.000000   0.454545  0.275329   0.000000   0.615385  \n","Random Forest             0.000000   0.000000  0.000000   0.000000   0.000000  \n","\n","[3 rows x 30 columns]\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Placeholder for best hyperparameters (you can modify these values)\n","best_nb_params = {'alpha': 1.0}\n","best_rf_params = {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5}\n","best_lr_params = {'C': 1.0}\n","\n","X = df['text'].values\n","y = df['label'].values\n","\n","skf = StratifiedKFold(n_splits=5)\n","\n","for train_index, test_index in skf.split(X, y):\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","\n","    vect = CountVectorizer(ngram_range=(1, 2), max_features=10000, stop_words=\"english\")\n","    X_train_dtm = vect.fit_transform(X_train)\n","    X_test_dtm = vect.transform(X_test)\n","\n","    # Train and predict using the models\n","    models = {\n","        \"Multinomial Naive Bayes\": MultinomialNB(**best_nb_params),\n","        \"Random Forest\": RandomForestClassifier(random_state=1, **best_rf_params),\n","        \"Logistic Regression\": LogisticRegression(max_iter=1000, **best_lr_params)\n","    }\n","\n","    predictions = {}\n","\n","    for model_name, model in models.items():\n","        model.fit(X_train_dtm, y_train)\n","        preds = model.predict(X_test_dtm)\n","        predictions[model_name] = preds\n","\n","    # Convert predictions to DataFrame\n","    predicted_df = pd.DataFrame(predictions)\n","    predicted_df['True Label'] = y_test\n","\n","    results = []\n","\n","    # Bootstrap by randomly sampling from predicted_df\n","    for _ in range(1000):\n","        sample_df = predicted_df.sample(len(predicted_df), replace=True)\n","\n","        for model_name in models.keys():\n","            preds = sample_df[model_name].values\n","            true_labels = sample_df['True Label'].values\n","\n","            accuracy = accuracy_score(true_labels, preds)\n","            positive_precision = precision_score(true_labels, preds, labels=[1], average='binary')\n","            positive_recall = recall_score(true_labels, preds, labels=[1], average='binary')\n","            positive_f1 = f1_score(true_labels, preds, labels=[1], average='binary')\n","            negative_precision = precision_score(true_labels, preds, labels=[0], average='binary')\n","            negative_recall = recall_score(true_labels, preds, labels=[0], average='binary')\n","            negative_f1 = f1_score(true_labels, preds, labels=[0], average='binary')\n","            macro_precision = (positive_precision + negative_precision) / 2\n","            macro_recall = (positive_recall + negative_recall) / 2\n","            macro_f1 = (positive_f1 + negative_f1) / 2\n","\n","            results.append({\n","                'Model': model_name,\n","                'Accuracy': accuracy,\n","                'Positive Precision': positive_precision,\n","                'Positive Recall': positive_recall,\n","                'Positive F1': positive_f1,\n","                'Negative Precision': negative_precision,\n","                'Negative Recall': negative_recall,\n","                'Negative F1': negative_f1,\n","                'Macro Precision': macro_precision,\n","                'Macro Recall': macro_recall,\n","                'Macro F1': macro_f1\n","            })\n","\n","    results_df = pd.DataFrame(results)\n","\n","    # Calculate mean and confidence intervals\n","    summary = results_df.groupby('Model').agg({\n","        metric: ['mean', lambda x: np.percentile(x, 2.5), lambda x: np.percentile(x, 97.5)]\n","        for metric in ['Accuracy', 'Positive Precision', 'Positive Recall', 'Positive F1', 'Negative Precision', 'Negative Recall', 'Negative F1', 'Macro Precision', 'Macro Recall', 'Macro F1']\n","    })\n","\n","    print(summary)\n","\n","summary\n","\n","summary.to_csv(f\"summary_models_ndvrs_{topic_name}_bag_of_words.csv\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pCIM_nfhnQGn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705615581996,"user_tz":300,"elapsed":8,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"}},"outputId":"fddb63e8-bee7-4d3e-e18d-7f3292ef3114"},"outputs":[{"output_type":"stream","name":"stdout","text":["                         Accuracy                       Positive Precision  \\\n","                             mean <lambda_0> <lambda_1>               mean   \n","Model                                                                        \n","Logistic Regression      0.731130   0.565217   0.913043           0.821362   \n","Multinomial Naive Bayes  0.600652   0.391304   0.782609           0.609894   \n","Random Forest            0.518348   0.304348   0.739130           0.000000   \n","\n","                                              Positive Recall             \\\n","                        <lambda_0> <lambda_1>            mean <lambda_0>   \n","Model                                                                      \n","Logistic Regression       0.428571        1.0        0.491659   0.199545   \n","Multinomial Naive Bayes   0.000000        1.0        0.190210   0.000000   \n","Random Forest             0.000000        0.0        0.000000   0.000000   \n","\n","                                   Positive F1  ... Negative F1  \\\n","                        <lambda_1>        mean  ...  <lambda_1>   \n","Model                                           ...               \n","Logistic Regression       0.800000    0.599001  ...    0.857143   \n","Multinomial Naive Bayes   0.454545    0.275329  ...    0.615385   \n","Random Forest             0.000000    0.000000  ...    0.000000   \n","\n","                        Macro Precision                       Macro Recall  \\\n","                                   mean <lambda_0> <lambda_1>         mean   \n","Model                                                                        \n","Logistic Regression            0.821362   0.428571        1.0     0.491659   \n","Multinomial Naive Bayes        0.609894   0.000000        1.0     0.190210   \n","Random Forest                  0.000000   0.000000        0.0     0.000000   \n","\n","                                               Macro F1                        \n","                        <lambda_0> <lambda_1>      mean <lambda_0> <lambda_1>  \n","Model                                                                          \n","Logistic Regression       0.199545   0.800000  0.599001   0.285714   0.857143  \n","Multinomial Naive Bayes   0.000000   0.454545  0.275329   0.000000   0.615385  \n","Random Forest             0.000000   0.000000  0.000000   0.000000   0.000000  \n","\n","[3 rows x 30 columns]\n"]}],"source":["print(summary)"]},{"cell_type":"markdown","source":["# Save Models"],"metadata":{"id":"pXE3Gp_zYANh"}},{"cell_type":"code","source":["# Save models\n","# /content/drive/MyDrive/nvdrs_narratives/round_1_annotation_topics/breakup_lr_model.pkl\n","#/content/drive/MyDrive/nvdrs_narratives/round_1_annotation_topics/child_custody_loss_lr_model.pkl\n","# /content/drive/MyDrive/nvdrs_narratives/round_1_annotation_topics/divorce_lr_model.pkl\n","# /content/drive/MyDrive/nvdrs_narratives/round_1_annotation_topics/pet_loss_lr_model.pkl\n","# /content/drive/MyDrive/nvdrs_narratives/round_1_annotation_topics/social_isolation_rf_model.pkl\n","# /content/drive/MyDrive/nvdrs_narratives/round_1_annotation_topics/eviction_or_move_lr_model.pkl\n","\n","# Save the best model\n","import pickle\n","pickle.dump(best_lr_model , open('eviction_or_move_lr_model.pkl','wb'))\n","\n","# Loading model to compare the results\n","test_model = pickle.load(open('social_isolation_rf_model.pkl','rb'))"],"metadata":{"id":"idHkXsbxX_Sn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fv-ngBmj9W6n"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Get feature importances from the best Random Forest model\n","feature_importances = best_rf_model.feature_importances_\n","\n","# Get the names of the features (tokens)\n","feature_names = np.array(vect.get_feature_names_out())\n","\n","# Sort feature importances in descending order\n","sorted_indices = np.argsort(feature_importances)[::-1]\n","\n","# Get the top 35 tokens and their importances\n","top_tokens = feature_names[sorted_indices][:30]\n","top_importances = feature_importances[sorted_indices][:30]\n","\n","# Create a bar chart\n","plt.figure(figsize=(12, 8))\n","plt.barh(range(len(top_tokens)), top_importances, align='center')\n","plt.yticks(range(len(top_tokens)), top_tokens)\n","plt.xlabel('Feature Importance (Gini Index)')\n","plt.ylabel('Token')\n","plt.title(f'Top 30 {topic_name} Tokens by Feature Importance (Random Forest)')\n","plt.gca().invert_yaxis()  # Invert y-axis to show the most important tokens at the top\n","plt.savefig(f\"{topic_name}_feature_importance_plot.png\", bbox_inches='tight')  # Save the figure before showing it\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UQaH-5o1WBXO"},"outputs":[],"source":["# Calculate feature contributions\n","coefs = best_lr_model.coef_  # Coefficients for each feature\n","feature_names = vect.get_feature_names_out()\n","\n","# Create a DataFrame to store feature contributions\n","contributions_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefs[0]})\n","\n","# Sort the DataFrame by the absolute value of coefficients to identify significant features\n","contributions_df['Absolute_Coefficient'] = np.abs(contributions_df['Coefficient'])\n","contributions_df = contributions_df.sort_values(by='Absolute_Coefficient', ascending=False)\n","\n","# Select the top N significant features for the plot\n","top_features = contributions_df.head(30)\n","\n","# Determine the color for each bar based on the coefficient value\n","colors = ['red' if coef > 0 else 'blue' for coef in top_features['Coefficient']]\n","\n","# Plot the feature contributions\n","plt.figure(figsize=(12, 8))\n","plt.barh(top_features['Feature'], top_features['Coefficient'], align='center', color=colors)\n","plt.xlabel('Feature Contribution')\n","plt.title(f'Top 30 {topic_name} Feature Contributions (Logistic Regression)')\n","plt.gca().invert_yaxis()  # Invert y-axis to show the most significant features at the top\n","plt.savefig(f\"{topic_name}_feature_contributions_plot.png\", bbox_inches='tight')  # Save the figure before showing it\n","plt.show()\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1pCcOmnDV_2qulSSrabOmO5udrwjBhPY9","timestamp":1701277815024},{"file_id":"10HBWC8ZHpQrfZucexzuRGuQDGOMVG1Qm","timestamp":1696344369812}],"authorship_tag":"ABX9TyPUDofOS2cwKnq7UM+kFPO3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}