{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10421,"status":"ok","timestamp":1707863971282,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"EjBVYUZOA-fj","outputId":"3e668237-b0e7-496a-f38a-c811f1181123"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"]}],"source":["!pip install transformers\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","\n","\n","\n","import torch\n","torch.cuda.empty_cache()\n","import seaborn as sns\n","import transformers\n","import json\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import RobertaModel, RobertaTokenizer\n","import logging\n","logging.basicConfig(level=logging.ERROR)\n","from google.colab import output\n","import seaborn as sn\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","#GPU usage setup\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","import random\n","random.seed(1)\n","np.random.seed(1)\n","torch.cuda.manual_seed(1)\n","torch.manual_seed(1)\n","import time\n","start_time = time.time()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1650,"status":"ok","timestamp":1707863972929,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"F8s_woLsBjTn","outputId":"e35afb1b-a97c-4964-a28b-b186232d3dee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["# mount drive to access data\n","from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1707863972929,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"xhdn4k1DCdr2","outputId":"3167abf7-8096-4d64-d4e5-d590e3549407"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/nvdrs_narratives/round_1_annotation_topics\n"," breakup_feature_contributions_plot.png\n"," breakup_feature_importance_plot.png\n"," breakup_lr_model.pkl\n"," breakup_sample_0_sd_completed.csv\n"," breakup_sampled_sd_completed.csv\n"," child_custody_loss_feature_contributions_plot.png\n"," child_custody_loss_feature_importance_plot.png\n"," child_custody_loss_lr_model.pkl\n"," child_feature_contributions_plot.png\n"," child_feature_importance_plot.png\n"," child_sample_0_sd_completed.csv\n"," child_sampled_dw_completed.csv\n"," divorce_feature_contributions_plot.png\n"," divorce_feature_importance_plot.png\n"," divorce_lr_model.pkl\n"," divorce_sample_0_dw_completed.csv\n"," divorce_sampled_sr_completed.csv\n"," eviction_feature_contributions_plot.png\n"," eviction_feature_importance_plot.png\n"," eviction_move_roberta.pth\n"," eviction_or_move_lr_model.pkl\n","'eviction or move_sample_0_sp_completed.csv'\n","'eviction or move_sampled_sp_completed.csv'\n"," nvdrs_breakup_model_results.csv\n"," nvdrs_breakup_model_results.gsheet\n","'nvdrs_child custody loss_model_results.csv'\n"," nvdrs_child_custody_loss_model_results.csv\n","'nvdrs_child custody loss_model_results.gsheet'\n"," nvdrs_child_model_results.csv\n"," nvdrs_divorce_model_results.csv\n"," nvdrs_eviction_model_results.csv\n","'nvdrs_eviction or move_model_results.csv'\n","'nvdrs_eviction or move_model_results.gsheet'\n"," nvdrs_merged_with_predictions.csv\n","'nvdrs_pet loss_model_results.csv'\n"," nvdrs_pet_loss_model_results.csv\n"," nvdrs_pet_model_results.csv\n"," nvdrs_social_isolation_chronic_model_results.csv\n","'nvdrs_social isolation_model_results (1).gsheet'\n","'nvdrs_social isolation_model_results.csv'\n"," nvdrs_social_isolation_model_results.csv\n","'nvdrs_social isolation_model_results.gsheet'\n"," pet_feature_contributions_plot.png\n"," pet_feature_importance_plot.png\n"," pet_loss_feature_contributions_plot.png\n"," pet_loss_feature_importance_plot.png\n"," pet_loss_lr_model.pkl\n"," pet_sample_0_sr_completed.csv\n"," pet_sampled_dw_completed.csv\n"," predictions.csv\n"," social_isolation_chronic_feature_contributions_plot.png\n"," social_isolation_chronic_feature_importance_plot.png\n"," social_isolation_chronic_sampled_dw_completed.csv\n"," social_isolation_chronic_sampled_dw_completed_revised.csv\n","'social_isolation_chronic_sampled_sp annotated_01.17.24.csv'\n"," social_isolation_feature_contributions_plot.png\n"," social_isolation_feature_importance_plot.png\n"," social_isolation_rf_model.pkl\n"," social_isolation_sample_0_dw_completed.csv\n"," summary_models_ndvrs_breakup_bag_of_words.csv\n"," summary_models_ndvrs_breakupchild_bag_of_words.csv\n"," summary_models_ndvrs_child_bag_of_words.csv\n"," summary_models_ndvrs_childchild_bag_of_words.csv\n","'summary_models_ndvrs_child custody loss_bag_of_words.csv'\n"," summary_models_ndvrs_child_custody_loss_bag_of_words.csv\n"," summary_models_ndvrs_divorce_bag_of_words.csv\n"," summary_models_ndvrs_divorcechild_bag_of_words.csv\n"," summary_models_ndvrs_eviction_bag_of_words.csv\n"," summary_models_ndvrs_evictionchild_bag_of_words.csv\n","'summary_models_ndvrs_eviction or move_bag_of_words.csv'\n"," summary_models_ndvrs_petchild_bag_of_words.csv\n","'summary_models_ndvrs_pet loss_bag_of_words.csv'\n"," summary_models_ndvrs_pet_loss_bag_of_words.csv\n","'summary_models_ndvrs_social isolation_bag_of_words.csv'\n"," summary_models_ndvrs_social_isolation_bag_of_words.csv\n"," summary_models_ndvrs_social_isolation_chronicchild_bag_of_words.csv\n"]}],"source":["\n","%cd /content/drive/MyDrive/nvdrs_narratives/round_1_annotation_topics\n","\n","%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1707863972929,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"MykjdrQ5OV-K","outputId":"7a73ff58-287b-4abd-aa5f-4591b0645cf1"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 100 entries, 0 to 49\n","Data columns (total 10 columns):\n"," #   Column                      Non-Null Count  Dtype \n","---  ------                      --------------  ----- \n"," 0   IncidentID                  100 non-null    int64 \n"," 1   NarrativeCME                50 non-null     object\n"," 2   matched_term_y              76 non-null     object\n"," 3   CME_CircumstancesOtherText  6 non-null      object\n"," 4   NarrativeLE                 68 non-null     object\n"," 5   matched_term_x              82 non-null     object\n"," 6   LE_CircumstancesOtherText   11 non-null     object\n"," 7   topic_name                  100 non-null    object\n"," 8   topic_relevant_annotation   100 non-null    int64 \n"," 9   comments                    25 non-null     object\n","dtypes: int64(2), object(8)\n","memory usage: 8.6+ KB\n"]}],"source":["# Read the Sample first round csv file\n","#df = pd.read_csv(\"pet_sampled_dw_completed.csv\")\n","\n","df1 = pd.read_csv(\"child_sample_0_sd_completed.csv\")\n","df2 = pd.read_csv(\"child_sampled_dw_completed.csv\")\n","# Bind/concatenate rows from additional sample, make sure we preserve column names\n","df = pd.concat([df1, df2])\n","\n","df.info()\n","topic_name = \"child support loss\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SryaBibHD1wA"},"outputs":[],"source":["df['label'] = df['topic_relevant_annotation']\n","df.drop(['IncidentID','LE_CircumstancesOtherText','CME_CircumstancesOtherText','topic_name','comments'], axis=1)\n","del df['IncidentID'], df['LE_CircumstancesOtherText'],df['CME_CircumstancesOtherText'], df['topic_name'], df['comments'], df['topic_relevant_annotation']"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Assuming df is your existing DataFrame\n","# df = pd.DataFrame(...)  # your original DataFrame\n","\n","def transform_dataframe(original_df):\n","    # Create an empty DataFrame with the desired structure\n","    transformed_df = pd.DataFrame(columns=['text', 'matched_term', 'label'])\n","\n","    # Iterate over each row in the original DataFrame\n","    for idx, row in original_df.iterrows():\n","        # Logic for handling NarrativeLE and NarrativeCME\n","        if pd.isna(row['NarrativeLE']) or row['NarrativeLE'] == '':\n","            transformed_df = transformed_df.append({\n","                'text': row['NarrativeCME'],\n","                'matched_term': row['matched_term_y'],\n","                'label': row['label']\n","            }, ignore_index=True)\n","        elif pd.isna(row['NarrativeCME']) or row['NarrativeCME'] == '':\n","            transformed_df = transformed_df.append({\n","                'text': row['NarrativeLE'],\n","                'matched_term': row['matched_term_x'],\n","                'label': row['label']\n","            }, ignore_index=True)\n","        else:\n","            # Create two new rows if both columns have values\n","            transformed_df = transformed_df.append([\n","                {\n","                    'text': row['NarrativeLE'],\n","                    'matched_term': row['matched_term_x'],\n","                    'label': row['label']\n","                },\n","                {\n","                    'text': row['NarrativeCME'],\n","                    'matched_term': row['matched_term_y'],\n","                    'label': row['label']\n","                }\n","            ], ignore_index=True)\n","\n","    return transformed_df\n","\n","# Apply the transformation\n","transformed_df = transform_dataframe(df)\n","\n","# Output the transformed DataFrame\n","transformed_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"a3L67_Gf4Or0","executionInfo":{"status":"ok","timestamp":1707863972930,"user_tz":300,"elapsed":13,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"}},"outputId":"3f36100b-2f07-40c4-f281-5e525edf30cf","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append([\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n","<ipython-input-6-f20a6d615aa2>:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  transformed_df = transformed_df.append({\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                  text  \\\n","0    Male victim died of a suspected drug overdose ...   \n","1    On 10/25/2015 officers responded to a suicidal...   \n","2    On 3/6/2015 Officers responded to a check welf...   \n","3    Victim, a 15-year-old white male, hung himself...   \n","4    Victim, a 15-year-old white male, hung himself...   \n","..                                                 ...   \n","113  Police were summoned when friends could not co...   \n","114  Victim is a 37 year old white male. He was fou...   \n","115  V was a 27 year old, non-Hispanic, white, male...   \n","116  The Victim (V) was a 25 year old white male in...   \n","117  V was W/F/47. V was found in her residence unr...   \n","\n","               matched_term label  \n","0    ['protective custody']     0  \n","1               ['custody']     0  \n","2               ['custody']     0  \n","3               ['custody']     1  \n","4               ['custody']     1  \n","..                      ...   ...  \n","113             ['custody']     0  \n","114    ['see his children']     1  \n","115    ['see his children']     1  \n","116             ['custody']     0  \n","117        ['lost custody']     1  \n","\n","[118 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-334af98f-be21-4378-8d3e-1aaf070787b2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>matched_term</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Male victim died of a suspected drug overdose ...</td>\n","      <td>['protective custody']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>On 10/25/2015 officers responded to a suicidal...</td>\n","      <td>['custody']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>On 3/6/2015 Officers responded to a check welf...</td>\n","      <td>['custody']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Victim, a 15-year-old white male, hung himself...</td>\n","      <td>['custody']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Victim, a 15-year-old white male, hung himself...</td>\n","      <td>['custody']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>Police were summoned when friends could not co...</td>\n","      <td>['custody']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>114</th>\n","      <td>Victim is a 37 year old white male. He was fou...</td>\n","      <td>['see his children']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>115</th>\n","      <td>V was a 27 year old, non-Hispanic, white, male...</td>\n","      <td>['see his children']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>116</th>\n","      <td>The Victim (V) was a 25 year old white male in...</td>\n","      <td>['custody']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>117</th>\n","      <td>V was W/F/47. V was found in her residence unr...</td>\n","      <td>['lost custody']</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>118 rows Ã— 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-334af98f-be21-4378-8d3e-1aaf070787b2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-334af98f-be21-4378-8d3e-1aaf070787b2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-334af98f-be21-4378-8d3e-1aaf070787b2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a13c5c50-d84c-461e-8fde-8dcf80ca2393\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a13c5c50-d84c-461e-8fde-8dcf80ca2393')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a13c5c50-d84c-461e-8fde-8dcf80ca2393 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_d43c03f1-e265-40dc-8de5-7bfb94e9ba5c\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('transformed_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_d43c03f1-e265-40dc-8de5-7bfb94e9ba5c button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('transformed_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1707863972930,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"-5X5Ki-nISBo","outputId":"9c2d0ae6-7495-4ac9-e688-aefa774c6c20","collapsed":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  text  \\\n","0    Male victim died of a suspected drug overdose ...   \n","1    On 10/25/2015 officers responded to a suicidal...   \n","2    On 3/6/2015 Officers responded to a check welf...   \n","3    Victim, a 15-year-old white male, hung himself...   \n","4    Victim, a 15-year-old white male, hung himself...   \n","..                                                 ...   \n","113  Police were summoned when friends could not co...   \n","114  Victim is a 37 year old white male. He was fou...   \n","115  V was a 27 year old, non-Hispanic, white, male...   \n","116  The Victim (V) was a 25 year old white male in...   \n","117  V was W/F/47. V was found in her residence unr...   \n","\n","               matched_term  label  \n","0    ['protective custody']      0  \n","1               ['custody']      0  \n","2               ['custody']      0  \n","3               ['custody']      1  \n","4               ['custody']      1  \n","..                      ...    ...  \n","113             ['custody']      0  \n","114    ['see his children']      1  \n","115    ['see his children']      1  \n","116             ['custody']      0  \n","117        ['lost custody']      1  \n","\n","[118 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-a113cf8b-d5f3-4578-8a98-2a531c9f6eac\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>matched_term</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Male victim died of a suspected drug overdose ...</td>\n","      <td>['protective custody']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>On 10/25/2015 officers responded to a suicidal...</td>\n","      <td>['custody']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>On 3/6/2015 Officers responded to a check welf...</td>\n","      <td>['custody']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Victim, a 15-year-old white male, hung himself...</td>\n","      <td>['custody']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Victim, a 15-year-old white male, hung himself...</td>\n","      <td>['custody']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>Police were summoned when friends could not co...</td>\n","      <td>['custody']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>114</th>\n","      <td>Victim is a 37 year old white male. He was fou...</td>\n","      <td>['see his children']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>115</th>\n","      <td>V was a 27 year old, non-Hispanic, white, male...</td>\n","      <td>['see his children']</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>116</th>\n","      <td>The Victim (V) was a 25 year old white male in...</td>\n","      <td>['custody']</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>117</th>\n","      <td>V was W/F/47. V was found in her residence unr...</td>\n","      <td>['lost custody']</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>118 rows Ã— 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a113cf8b-d5f3-4578-8a98-2a531c9f6eac')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a113cf8b-d5f3-4578-8a98-2a531c9f6eac button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a113cf8b-d5f3-4578-8a98-2a531c9f6eac');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-66649dc1-ee46-42a9-ae06-f68a116eee29\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66649dc1-ee46-42a9-ae06-f68a116eee29')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-66649dc1-ee46-42a9-ae06-f68a116eee29 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_2bcbcb91-66e5-4d3c-8820-03f66b9ba24c\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_2bcbcb91-66e5-4d3c-8820-03f66b9ba24c button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":7}],"source":["df = transformed_df\n","cols = ['text', 'matched_term']\n","df['text'] = df[cols].apply(lambda row: '</s>'.join(row.values.astype(str)), axis=1)\n","df[\"label\"] = df[\"label\"].astype(int)\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2030,"status":"ok","timestamp":1707863974952,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"nxD6x484KlqK","outputId":"1bcba87d-0c8a-4f20-cf25-c0ba40550899"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["MAX_LEN = 128\n","TRAIN_BATCH_SIZE = 16\n","VALID_BATCH_SIZE = 16\n","EPOCHS = 10\n","LEARNING_RATE = 1e-05\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bzbOHNzfKsVB"},"outputs":[],"source":["from torch.utils.data import Dataset\n","import torch\n","\n","class BiasData(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.text = dataframe.text\n","        self.targets = self.data.label\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, index):\n","        text = str(self.text[index])\n","        text = \" \".join(text.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs.get(\"token_type_ids\", [0] * len(ids))  # Defaulting token_type_ids to zeros if not returned\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets': torch.tensor(self.targets[index], dtype=torch.long)  # Ensured dtype is torch.long\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1707863974954,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"JkIiCy7ojUkf","outputId":"7dc17822-e2be-46bb-8031-ef96da071c14"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 118 entries, 0 to 117\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   text    118 non-null    object\n"," 1   label   118 non-null    int64 \n","dtypes: int64(1), object(1)\n","memory usage: 2.0+ KB\n"]}],"source":["newdf = df[['text','label']]\n","newdf.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1707863974955,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"QEGaXkeYKvhY","outputId":"1b8e6178-a0f0-4abf-d73e-6fc66d22b2f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["FULL Dataset: (118, 2)\n","TRAIN Dataset: (94, 2)\n","TEST Dataset: (24, 2)\n"]}],"source":["train_size = 0.8\n","train_data=newdf.sample(frac=train_size,random_state=0)\n","test_data=newdf.drop(train_data.index).reset_index(drop=True)\n","train_data = train_data.reset_index(drop=True)\n","\n","print(\"FULL Dataset: {}\".format(newdf.shape))\n","print(\"TRAIN Dataset: {}\".format(train_data.shape))\n","print(\"TEST Dataset: {}\".format(test_data.shape))\n","\n","training_set = BiasData(train_data, tokenizer, MAX_LEN)\n","testing_set = BiasData(test_data, tokenizer, MAX_LEN)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4995,"status":"ok","timestamp":1707863979943,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"JdPb5M_hmGjG","outputId":"28919c77-b5df-41db-ba0e-4116e485fa41"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1])"]},"metadata":{},"execution_count":12}],"source":["train_data['label'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1707863979943,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"hhF881I2kdtP","outputId":"89c35343-44aa-4b0b-d183-1a14f713a8fa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1])"]},"metadata":{},"execution_count":13}],"source":["test_data['label'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iMCNe4KJK1nT"},"outputs":[],"source":["train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","training_loader = DataLoader(training_set, **train_params)\n","testing_loader = DataLoader(testing_set, **test_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F9_lGeSnK4Mn"},"outputs":[],"source":["from transformers import RobertaConfig\n","\n","config = RobertaConfig.from_pretrained(\"roberta-base\")\n","config.output_attentions = True\n","\n","class RobertaClass(torch.nn.Module):\n","    def __init__(self):\n","        super(RobertaClass, self).__init__()\n","        self.l1 = RobertaModel.from_pretrained(\"roberta-base\", config=config)\n","        self.pre_classifier = torch.nn.Linear(768, 768)\n","        self.dropout = torch.nn.Dropout(0.0)\n","        self.classifier = torch.nn.Linear(768, 2)\n","\n","    def forward(self, input_ids, attention_mask):\n","        # Get the hidden states, pooler output, and attention weights\n","        last_hidden_state, pooler_output, all_attentions = self.l1(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n","        pooler = last_hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output, all_attentions\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1653,"status":"ok","timestamp":1707863981593,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"ahZoH1PJLBo7","outputId":"ac556d33-863a-461a-d898-a59de05e1219"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["RobertaClass(\n","  (l1): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (dropout): Dropout(p=0.0, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":16}],"source":["model = RobertaClass()\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L2Tb_Xs8K7uM"},"outputs":[],"source":["# Creating the loss function and optimizer\n","loss_function = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AL_y2UG-LIjb"},"outputs":[],"source":["def calcuate_accuracy(preds, targets):\n","    n_correct = (preds==targets).sum().item()\n","    return n_correct"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KC6oL35HLKRN"},"outputs":[],"source":["def train(epoch):\n","    tr_loss = 0\n","    n_correct = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    model.train()\n","    for _,data in tqdm(enumerate(training_loader, 0)):\n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.long)\n","\n","        # Extract the logits (output) from the returned tuple\n","        logits, attention_weights = model(ids, mask)\n","\n","        # Use the logits when computing the loss\n","        loss = loss_function(logits, targets)\n","        tr_loss += loss.item()\n","        big_val, big_idx = torch.max(logits.data, dim=1)\n","        n_correct += calcuate_accuracy(big_idx, targets)\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += targets.size(0)\n","\n","        if _ % 5000 == 0:\n","            loss_step = tr_loss / nb_tr_steps\n","            accu_step = (n_correct * 100) / nb_tr_examples\n","            print(f\"Training Loss: {loss_step}\")\n","            print(f\"Training Accuracy: {accu_step}\")\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f\"Logits shape: {logits.shape}, Targets shape: {targets.shape}\")\n","    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct * 100) / nb_tr_examples}')\n","    epoch_loss = tr_loss / nb_tr_steps\n","    epoch_accu = (n_correct * 100) / nb_tr_examples\n","    print(f\"Training Loss Epoch: {epoch_loss}\")\n","    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n","\n","    return\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40520,"status":"ok","timestamp":1707864022506,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"Iw77-0LpLMr2","outputId":"31730f08-c67b-4f27-8821-663bfc4e68b0"},"outputs":[{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.6999179124832153\n","Training Accuracy: 43.75\n"]},{"output_type":"stream","name":"stderr","text":["\r1it [00:01,  1.09s/it]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","4it [00:08,  1.72s/it]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","5it [00:10,  1.59s/it]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","6it [00:11,  1.87s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Logits shape: torch.Size([14, 2]), Targets shape: torch.Size([14])\n","The Total Accuracy for Epoch 0: 57.4468085106383\n","Training Loss Epoch: 0.6894948383172353\n","Training Accuracy Epoch: 57.4468085106383\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","1it [00:00,  6.72it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.6656309962272644\n","Training Accuracy: 56.25\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:00,  3.02it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","6it [00:02,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Logits shape: torch.Size([14, 2]), Targets shape: torch.Size([14])\n","The Total Accuracy for Epoch 1: 57.4468085106383\n","Training Loss Epoch: 0.6751967072486877\n","Training Accuracy Epoch: 57.4468085106383\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","1it [00:00,  6.41it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.7131946086883545\n","Training Accuracy: 43.75\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","2it [00:01,  1.63it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","5it [00:02,  2.39it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","6it [00:03,  1.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Logits shape: torch.Size([14, 2]), Targets shape: torch.Size([14])\n","The Total Accuracy for Epoch 2: 57.4468085106383\n","Training Loss Epoch: 0.6759064992268881\n","Training Accuracy Epoch: 57.4468085106383\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","1it [00:00,  6.54it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.7157880663871765\n","Training Accuracy: 43.75\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","4it [00:01,  2.94it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","5it [00:02,  1.75it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","6it [00:03,  1.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Logits shape: torch.Size([14, 2]), Targets shape: torch.Size([14])\n","The Total Accuracy for Epoch 3: 57.4468085106383\n","Training Loss Epoch: 0.6767211357752482\n","Training Accuracy Epoch: 57.4468085106383\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","1it [00:00,  6.44it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.7530617713928223\n","Training Accuracy: 37.5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","4it [00:01,  2.93it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","5it [00:02,  1.75it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","6it [00:03,  1.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Logits shape: torch.Size([14, 2]), Targets shape: torch.Size([14])\n","The Total Accuracy for Epoch 4: 57.4468085106383\n","Training Loss Epoch: 0.6637118657430013\n","Training Accuracy Epoch: 57.4468085106383\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","1it [00:00,  6.80it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.7115126252174377\n","Training Accuracy: 50.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","4it [00:01,  2.88it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","5it [00:01,  2.88it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","6it [00:02,  2.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Logits shape: torch.Size([14, 2]), Targets shape: torch.Size([14])\n","The Total Accuracy for Epoch 5: 60.638297872340424\n","Training Loss Epoch: 0.6845879952112833\n","Training Accuracy Epoch: 60.638297872340424\n"]},{"output_type":"stream","name":"stderr","text":["1it [00:00,  3.07it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","2it [00:00,  1.97it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.658477246761322\n","Training Accuracy: 68.75\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:01,  2.29it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","6it [00:02,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Logits shape: torch.Size([14, 2]), Targets shape: torch.Size([14])\n","The Total Accuracy for Epoch 6: 65.95744680851064\n","Training Loss Epoch: 0.6582038203875223\n","Training Accuracy Epoch: 65.95744680851064\n"]},{"output_type":"stream","name":"stderr","text":["1it [00:00,  2.44it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.6186739802360535\n","Training Accuracy: 93.75\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","4it [00:01,  2.59it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","6it [00:02,  2.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Logits shape: torch.Size([14, 2]), Targets shape: torch.Size([14])\n","The Total Accuracy for Epoch 7: 72.34042553191489\n","Training Loss Epoch: 0.6570801734924316\n","Training Accuracy Epoch: 72.34042553191489\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","1it [00:00,  6.41it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.6140677332878113\n","Training Accuracy: 75.0\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:00,  3.06it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","4it [00:01,  1.76it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","5it [00:02,  1.42it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","6it [00:03,  1.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Logits shape: torch.Size([14, 2]), Targets shape: torch.Size([14])\n","The Total Accuracy for Epoch 8: 70.2127659574468\n","Training Loss Epoch: 0.6188414096832275\n","Training Accuracy Epoch: 70.2127659574468\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","1it [00:00,  6.36it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.587214469909668\n","Training Accuracy: 75.0\n"]},{"output_type":"stream","name":"stderr","text":["3it [00:00,  2.99it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","4it [00:01,  1.72it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","5it [00:02,  1.40it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","6it [00:03,  1.88it/s]"]},{"output_type":"stream","name":"stdout","text":["Logits shape: torch.Size([14, 2]), Targets shape: torch.Size([14])\n","The Total Accuracy for Epoch 9: 70.2127659574468\n","Training Loss Epoch: 0.597067634264628\n","Training Accuracy Epoch: 70.2127659574468\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["for epoch in range(EPOCHS):\n","    train(epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EpjlKyM0GWAE"},"outputs":[],"source":["def calcuate_accuracy(preds, targets):\n","    n_correct = (preds==targets).sum().item()\n","    return n_correct"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YpMVbCFDLO1H"},"outputs":[],"source":["def valid(model, testing_loader):\n","    model.eval()\n","    n_correct = 0\n","    tr_loss = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","\n","    all_preds = []  # list to store predictions\n","    all_targets = []  # list to store original targets\n","    all_texts = []  # list to store original input texts\n","\n","    with torch.no_grad():\n","        for _, data in tqdm(enumerate(testing_loader, 0)):\n","            ids = data['ids'].to(device, dtype=torch.long)\n","            mask = data['mask'].to(device, dtype=torch.long)\n","            targets = data['targets'].to(device, dtype=torch.long)\n","\n","            # Extract the logits (output) from the returned tuple\n","            logits, attention_weights = model(ids, mask)\n","           # logits = logits.squeeze()\n","            print(f\"Batch size: {len(targets)}\")  # Print actual batch size\n","            print(f\"Logits shape: {logits.shape}, Targets shape: {targets.shape}\")\n","            # Use the logits when computing the loss and other operations\n","            loss = loss_function(logits, targets)\n","            tr_loss += loss.item()\n","            big_val, big_idx = torch.max(logits.data, dim=1)\n","\n","            all_preds.extend(big_idx.cpu().numpy())  # store predictions\n","            all_targets.extend(targets.cpu().numpy())  # store targets\n","\n","            all_texts.extend(data['ids'])  # store original input texts\n","\n","            n_correct += calcuate_accuracy(big_idx, targets)9\n","\n","            nb_tr_steps += 1\n","            nb_tr_examples += targets.size(0)\n","\n","            if _ % 5000 == 0:\n","                loss_step = tr_loss / nb_tr_steps\n","                accu_step = (n_correct * 100) / nb_tr_examples\n","                print(f\"Validation Loss: {loss_step}\")\n","                print(f\"Validation Accuracy: {accu_step}\")\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    epoch_accu = (n_correct * 100) / nb_tr_examples\n","\n","\n","    print(f\"Validation Loss Epoch: {epoch_loss}\")\n","    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n","\n","    # Print classification report\n","    report = classification_report(all_targets, all_preds)\n","    print(report)\n","\n","    # Confusion matrix\n","    cm = confusion_matrix(all_targets, all_preds)\n","    print(\"Confusion Matrix:\")\n","    print(cm)\n","\n","    # Create a DataFrame and save it\n","    df_predictions = pd.DataFrame({\n","        'Text': all_texts,\n","        'Original': all_targets,\n","        'Predicted': all_preds\n","    })\n","    df_predictions.to_csv('predictions.csv', index=False)\n","    print(df_predictions.head())\n","\n","    return epoch_accu\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pM6BRrHLTofg"},"source":["Initial Run -- one interation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1544,"status":"ok","timestamp":1707864023991,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":300},"id":"f7enVMoUVdph","outputId":"849c8337-de37-4280-a3ef-f73bc44a4100"},"outputs":[{"output_type":"stream","name":"stderr","text":["1it [00:00,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["Batch size: 16\n","Logits shape: torch.Size([16, 2]), Targets shape: torch.Size([16])\n","Validation Loss: 0.7173306345939636\n","Validation Accuracy: 43.75\n","Batch size: 8\n","Logits shape: torch.Size([8, 2]), Targets shape: torch.Size([8])\n"]},{"output_type":"stream","name":"stderr","text":["\r2it [00:00,  5.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss Epoch: 0.682496964931488\n","Validation Accuracy Epoch: 50.0\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.46      0.50        13\n","           1       0.46      0.55      0.50        11\n","\n","    accuracy                           0.50        24\n","   macro avg       0.50      0.50      0.50        24\n","weighted avg       0.51      0.50      0.50        24\n","\n","Confusion Matrix:\n","[[6 7]\n"," [5 6]]\n","                                                Text  Original  Predicted\n","0  [tensor(0), tensor(133), tensor(468), tensor(3...         1          1\n","1  [tensor(0), tensor(846), tensor(16), tensor(10...         0          0\n","2  [tensor(0), tensor(3103), tensor(1423), tensor...         1          1\n","3  [tensor(0), tensor(846), tensor(21), tensor(30...         0          0\n","4  [tensor(0), tensor(133), tensor(468), tensor(6...         0          1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","1it [00:00,  7.96it/s]"]},{"output_type":"stream","name":"stdout","text":["Batch size: 16\n","Logits shape: torch.Size([16, 2]), Targets shape: torch.Size([16])\n","Validation Loss: 0.7078904509544373\n","Validation Accuracy: 50.0\n"]},{"output_type":"stream","name":"stderr","text":["\r2it [00:00,  9.86it/s]"]},{"output_type":"stream","name":"stdout","text":["Batch size: 8\n","Logits shape: torch.Size([8, 2]), Targets shape: torch.Size([8])\n","Validation Loss Epoch: 0.6872171759605408\n","Validation Accuracy Epoch: 50.0\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.46      0.50        13\n","           1       0.46      0.55      0.50        11\n","\n","    accuracy                           0.50        24\n","   macro avg       0.50      0.50      0.50        24\n","weighted avg       0.51      0.50      0.50        24\n","\n","Confusion Matrix:\n","[[6 7]\n"," [5 6]]\n","                                                Text  Original  Predicted\n","0  [tensor(0), tensor(133), tensor(1802), tensor(...         0          1\n","1  [tensor(0), tensor(713), tensor(1718), tensor(...         1          0\n","2  [tensor(0), tensor(3750), tensor(2219), tensor...         0          1\n","3  [tensor(0), tensor(133), tensor(468), tensor(3...         1          1\n","4  [tensor(0), tensor(846), tensor(134), tensor(3...         0          0\n","test accuracy = 50.00%\n","Elapsed Time: 52.45 seconds\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["valid(model, testing_loader)\n","\n","acc = valid(model,testing_loader)\n","print(\"test accuracy = %0.2f%%\" % acc)\n","\n","end_time = time.time()\n","\n","elapsed_time = end_time - start_time\n","print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")"]},{"cell_type":"markdown","metadata":{"id":"xWDeu8OJSztN"},"source":["In order to account for variations in GPU states, we ran each of the models 10 times and provide the mean accuracy"]},{"cell_type":"markdown","metadata":{"id":"_mRxc1yZaZQ_"},"source":["\n","## Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_uEuLmPRaY6l"},"outputs":[],"source":["def predict_on_dataframe(df, model, tokenizer, max_len):\n","    model.eval()\n","    predictions = []\n","\n","    for index, row in df.iterrows():\n","        text = row['text']\n","        inputs = tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","        ids = torch.tensor([inputs['input_ids']], dtype=torch.long).to(device)\n","        mask = torch.tensor([inputs['attention_mask']], dtype=torch.long).to(device)\n","\n","        with torch.no_grad():\n","            logits, _ = model(ids, mask)  # Here we unpack the tuple\n","\n","        big_val, big_idx = torch.max(logits.data, dim=1)  # Use logits instead of outputs\n","        predictions.append(big_idx[0].item())\n","\n","    df['predictions'] = predictions\n","    return df\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_yCS7J9eSJOy","outputId":"3f2fd32f-c8f5-48a1-ba63-0ec058c7a73b","executionInfo":{"status":"ok","timestamp":1707864194098,"user_tz":300,"elapsed":4331,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}],"source":["predictions = predict_on_dataframe(newdf, model, tokenizer, max_len=512)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JeEEqX8wP7vz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707864203601,"user_tz":300,"elapsed":9505,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"}},"outputId":"54f01b89-fb74-42fb-910f-67f92c0246fe"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.4576271186440678, CI: (0.3644067796610169, 0.5423728813559322)\n","Positive Class Precision: 0.6666666666666666, CI: (0.0, 1.0)\n","Positive Class Recall: 0.03076923076923077, CI: (0.0, 0.07936507936507936)\n","Positive Class F1 Score: 0.05882352941176471, CI: (0.0, 0.14036323202372128)\n","Macro Precision: 0.5594202898550724, CI: (0.2076271186440678, 0.7606884057971014)\n","Macro Recall: 0.5059506531204645, CI: (0.4787296037296037, 0.5330516820671297)\n","Macro F1 Score: 0.3389355742296919, CI: (0.2804539932147442, 0.4057191634656424)\n"]}],"source":["from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","\n","\n","\n","true_labels = predictions['label'].tolist()\n","predicted_classes = predictions['predictions'].tolist()\n","\n","def bootstrap_metric(y_true, y_pred, metric_func, n_iterations=1000):\n","    bootstrap_values = []\n","    n_samples = len(y_true)\n","    for _ in range(n_iterations):\n","        indices = np.random.choice(np.arange(n_samples), size=n_samples, replace=True)\n","        bootstrap_true = np.array(y_true)[indices]\n","        bootstrap_pred = np.array(y_pred)[indices]\n","        value = metric_func(bootstrap_true, bootstrap_pred)\n","        bootstrap_values.append(value)\n","    return bootstrap_values\n","\n","# Direct calculation of metrics for point estimates\n","point_estimate_accuracy = accuracy_score(true_labels, predicted_classes)\n","point_estimate_f1_pos = f1_score(true_labels, predicted_classes, pos_label=1)\n","point_estimate_precision_pos = precision_score(true_labels, predicted_classes, pos_label=1)\n","point_estimate_recall_pos = recall_score(true_labels, predicted_classes, pos_label=1)\n","\n","point_estimate_f1_macro = f1_score(true_labels, predicted_classes, average='macro')\n","point_estimate_precision_macro = precision_score(true_labels, predicted_classes, average='macro')\n","point_estimate_recall_macro = recall_score(true_labels, predicted_classes, average='macro')\n","\n","# Bootstrapping each metric including accuracy\n","bootstrap_accuracy = bootstrap_metric(true_labels, predicted_classes, accuracy_score)\n","bootstrap_f1_pos = bootstrap_metric(true_labels, predicted_classes, lambda y_true, y_pred: f1_score(y_true, y_pred, pos_label=1))\n","bootstrap_precision_pos = bootstrap_metric(true_labels, predicted_classes, lambda y_true, y_pred: precision_score(y_true, y_pred, pos_label=1))\n","bootstrap_recall_pos = bootstrap_metric(true_labels, predicted_classes, lambda y_true, y_pred: recall_score(y_true, y_pred, pos_label=1))\n","\n","bootstrap_f1_macro = bootstrap_metric(true_labels, predicted_classes, lambda y_true, y_pred: f1_score(y_true, y_pred, average='macro'))\n","bootstrap_precision_macro = bootstrap_metric(true_labels, predicted_classes, lambda y_true, y_pred: precision_score(y_true, y_pred, average='macro'))\n","bootstrap_recall_macro = bootstrap_metric(true_labels, predicted_classes, lambda y_true, y_pred: recall_score(y_true, y_pred, average='macro'))\n","\n","# Computing 95% confidence intervals\n","def confidence_interval(data, alpha=0.05):\n","    lower_percentile = 100 * alpha / 2.\n","    upper_percentile = 100 * (1 - alpha / 2.)\n","    lower = np.percentile(data, lower_percentile)\n","    upper = np.percentile(data, upper_percentile)\n","    return lower, upper\n","\n","# Printing point estimates and confidence intervals\n","print(f\"Accuracy: {point_estimate_accuracy}, CI:\", confidence_interval(bootstrap_accuracy))\n","print(f\"Positive Class Precision: {point_estimate_precision_pos}, CI:\", confidence_interval(bootstrap_precision_pos))\n","print(f\"Positive Class Recall: {point_estimate_recall_pos}, CI:\", confidence_interval(bootstrap_recall_pos))\n","print(f\"Positive Class F1 Score: {point_estimate_f1_pos}, CI:\", confidence_interval(bootstrap_f1_pos))\n","\n","print(f\"Macro Precision: {point_estimate_precision_macro}, CI:\", confidence_interval(bootstrap_precision_macro))\n","print(f\"Macro Recall: {point_estimate_recall_macro}, CI:\", confidence_interval(bootstrap_recall_macro))\n","print(f\"Macro F1 Score: {point_estimate_f1_macro}, CI:\", confidence_interval(bootstrap_f1_macro))\n"]},{"cell_type":"markdown","metadata":{"id":"ZkTt_hZIT3Ug"},"source":["# Attention Visualization"]},{"cell_type":"code","source":["# Save model\n","import torch\n","\n","# Load model\n","# model is an instance of a custom class 'RobertaClass'\n","# Save the model's state_dict\n","torch.save(model, \"eviction_move_roberta.pth\")\n"],"metadata":{"id":"59nqMAvo5qyG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VaPTN75iFmPW"},"outputs":[],"source":["#import matplotlib.pyplot as plt\n","#import numpy as np\n","\n","# We already have the tokenized input_text\n","#print(tokens)\n","\n","# We also already have the attention tensor: attention_tensor\n","#attention_matrix = attention_tensor[0].detach().cpu().numpy()  # Convert tensor to numpy array\n","\n","# Identify the token position for the word \"needy\".\n","#needy_position = tokens.index('Ä needy') if 'Ä needy' in tokens else None\n","\n","# Identify non-padding tokens\n","#non_padding_positions = [pos for pos, token_id in enumerate(inputs['input_ids'][0].cpu().tolist()) if token_id != tokenizer.pad_token_id]\n","\n","#if needy_position is not None:\n","    # Use matplotlib to visualize the attention weights for this token.\n","\n","    # Restrict to only the non-padding tokens\n","#    restricted_attention = attention_matrix[0, 0, needy_position, non_padding_positions]\n","#    restricted_tokens = [tokens[pos] for pos in non_padding_positions]\n","\n","#    plt.figure(figsize=(10, 5))\n","#    plt.bar(np.arange(len(restricted_tokens)), restricted_attention)\n","#    plt.xlabel('Tokens')\n","#    plt.ylabel('Attention Weight')\n","#    plt.title('Attention Weights for the word \"needy\"')\n","#    plt.xticks(np.arange(len(restricted_tokens)), restricted_tokens, rotation=90)\n","#    plt.tight_layout()\n","#    plt.savefig(\"needy_attention_diagram.png\", format='png', dpi=300, bbox_inches='tight')\n","#    plt.show()\n","#else:\n","#    print(\"The word 'needy' not found in tokens.\")\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"25PdqdHOpKMl"},"source":["Notes for next time-- want to turn this script into a function where I can pass through the hyperparameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CryO7EM2Sizs"},"outputs":[],"source":["# svm baseline\n","\n","#from sklearn.pipeline import make_pipeline\n","#from sklearn.preprocessing import StandardScaler\n","#from sklearn.feature_extraction.text import CountVectorizer\n","#from sklearn.feature_extraction.text import TfidfTransformer\n","#from sklearn.svm import SVC\n","\n","#from sklearn.pipeline import Pipeline\n","#text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),('clf', SVC(gamma='auto'))])\n","#text_clf.fit(train_data['text'], train_data['label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EcwsAGpQVYf1"},"outputs":[],"source":["#docs_test = test_data['text']\n","#predicted = text_clf.predict(docs_test)\n","#np.mean(predicted == test_data['label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SKRxvs2e5QkB"},"outputs":[],"source":["#test_accs = []\n","#for i in range(10):\n","#  model = RobertaClass()\n","#  model.to(device)\n","#\n","#  loss_function = torch.nn.CrossEntropyLoss()\n","#  optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n","#\n","#  for epoch in range(EPOCHS):\n","#      train(epoch)\n","#  acc = valid(model, testing_loader)\n","#  #print(\"test accuracy = %0.2f%%\" % acc)\n","#  test_accs.append(acc)\n","\n","# mean_acc = sum(test_accs) / len(test_accs)\n","# print(\"MEAN ACCURACY = %0.2f%%\" % mean_acc)\n","# output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/d/d9/Wilhelm_Scream.ogg\").play()')\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1K5Hhe1n-BsRH544POv9GdeS3fWAS9i3R","timestamp":1707767274168},{"file_id":"1adeQKZGGMwDnOH9v9iFE5TnfRXLtRe3f","timestamp":1694185478102},{"file_id":"1vTaF4LdvnnH7MsQK-UXpUiKD_zssFn6s","timestamp":1694014124822},{"file_id":"17RUt3-zj2kAVyz958ylFeV8XuPs9EFP9","timestamp":1683607121007}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}